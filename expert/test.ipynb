{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kelvinchristian/miniconda3/envs/cs234/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from network_utils import MultiLayerCNN, np2torch, device\n",
    "from environment import Environment\n",
    "import matplotlib.pyplot as plt\n",
    "import hiddenlayer as hl\n",
    "from torchviz import make_dot\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------- #\n",
    "#                                     Input                                    #\n",
    "# ---------------------------------------------------------------------------- #\n",
    "# Can modify\n",
    "DATADIR = input(\"Enter dataset directory: \")\n",
    "if not os.path.exists(DATADIR):\n",
    "    print(\"Directory doesn't exists!\")\n",
    "    sys.exit(1)\n",
    "batch_size = 64\n",
    "TRAINING_MODE = input(\"Enter training mode (pick, place, all): \").lower()\n",
    "\n",
    "# ---------------------------------------------------------------------------- #\n",
    "#                                  Environment                                 #\n",
    "# ---------------------------------------------------------------------------- #\n",
    "\n",
    "env_generator = Environment()\n",
    "env = env_generator.create_env(fixed_placement=True)\n",
    "action_dim = env.action_dim\n",
    "with open(os.path.join(DATADIR, \"obs_dims.json\"), \"r\") as f:\n",
    "    obs_dict = json.load(f)\n",
    "    obs_dims = sum([v for k, v in obs_dict.items()])\n",
    "    train_dims = sum([v for k, v in obs_dict.items() if k in [\n",
    "        \"robot0_joint_pos_cos\",\n",
    "        \"robot0_joint_pos_sin\",\n",
    "        \"robot0_joint_vel\",\n",
    "        \"robot0_eef_pos\",\n",
    "        \"robot0_eef_quat\",\n",
    "        \"robot0_gripper_qpos\",\n",
    "        \"robot0_gripper_qvel\"\n",
    "    ]])\n",
    "\n",
    "with open(os.path.join(DATADIR, \"img_dims.json\"), \"r\") as f:\n",
    "    img_dims = sum([v for k, v in json.load(f).items()])\n",
    "\n",
    "# ---------------------------------------------------------------------------- #\n",
    "#                                    Helper                                    #\n",
    "# ---------------------------------------------------------------------------- #\n",
    "def create_dataloader(obs, actions, batch_size: int):\n",
    "    tensor_dataset = TensorDataset(np2torch(obs), np2torch(actions))\n",
    "    dataloader = DataLoader(tensor_dataset, batch_size=batch_size, shuffle=True)\n",
    "    return dataloader\n",
    "\n",
    "# ---------------------------------------------------------------------------- #\n",
    "#                                    Network                                   #\n",
    "# ---------------------------------------------------------------------------- #\n",
    "\n",
    "network = MultiLayerCNN(\n",
    "    obs_input_size=train_dims,\n",
    "    img_input_height=int(np.sqrt(img_dims / 3)),\n",
    "    img_input_width=int(np.sqrt(img_dims / 3)),\n",
    "    output_size=action_dim\n",
    ").to(device=device)\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr=0.00001)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------- #\n",
    "#                                   Training                                   #\n",
    "# ---------------------------------------------------------------------------- #\n",
    "\n",
    "obs_filepaths = [\n",
    "    os.path.join(DATADIR, filename)\\\n",
    "        for filename in os.listdir(DATADIR) if \"observations\" in filename\n",
    "]\n",
    "\n",
    "imgs_filepaths = [\n",
    "    os.path.join(DATADIR, filename)\\\n",
    "        for filename in os.listdir(DATADIR) if \"imgs\" in filename\n",
    "]\n",
    "\n",
    "combined_filepaths = []\n",
    "for filename in obs_filepaths:\n",
    "    common_name = \"_\" + \"_\".join(filename.split(\"_\")[-2:])\n",
    "    img_filename = [img_file for img_file in imgs_filepaths if common_name in img_file][0]\n",
    "    combined_filepaths.append((filename, img_filename))\n",
    "\n",
    "# Change the epochs here\n",
    "epochs = 10\n",
    "file_no = 0\n",
    "total_file = len(obs_filepaths) * epochs\n",
    "print(\"...Start Training...\")\n",
    "for i in range(epochs):\n",
    "    for filepath_obs, filepath_imgs in combined_filepaths:\n",
    "        print()\n",
    "        file_no += 1\n",
    "        try:\n",
    "            df_obs = pd.read_csv(filepath_obs)\n",
    "            df_imgs = pd.read_csv(filepath_imgs)\n",
    "            if TRAINING_MODE == \"pick\":\n",
    "                df_obs = df_obs[df_obs[\"subtask_id\"] <= 4]\n",
    "                df_imgs = df_imgs[df_imgs[\"subtask_id\"] <= 4]\n",
    "            elif TRAINING_MODE == \"place\":\n",
    "                df_obs = df_obs[df_obs[\"subtask_id\"] > 4]\n",
    "                df_imgs = df_imgs[df_imgs[\"subtask_id\"] > 4]\n",
    "        except:\n",
    "            continue\n",
    "        obs = df_obs.iloc[:, 0:train_dims]\n",
    "        imgs = df_imgs.iloc[:, 0:img_dims]\n",
    "        \n",
    "        obs_imgs = pd.concat([obs, imgs], axis=1).values.astype(np.float32)\n",
    "        actions = df_obs.iloc[:, obs_dims:(obs_dims+action_dim)].values.astype(np.float32)\n",
    "        \n",
    "        dataloader = create_dataloader(obs_imgs, actions, batch_size=batch_size)\n",
    "        n_dataloader = len(dataloader)\n",
    "        del obs, imgs, obs_imgs, actions, df_obs, df_imgs\n",
    "\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "\n",
    "            y_hat = network(X)\n",
    "            loss = criterion(y_hat, y)\n",
    "            break\n",
    "\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs234",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
